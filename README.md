# Understanding Toy Backdoors via Mechanistic Interpretability
**Abstract:** Backdoors and hidden harmful behaviour represent a severe risk to the safe deployment of deep neural networks. In this paper, we explore how a small Transformer model implements a toy backdoor behaviour. Our head attribution and activation patching experiments suggest that our model uses a single attention head to implement a simple backdoor.

Link to Paper: <br>
Link to Course Page: <br>
